{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import regex\n",
    "from datetime import datetime\n",
    "\n",
    "class tweet_data:\n",
    "    pass\n",
    "\n",
    "# D = tweet_data()\n",
    "# D.raw_data = rawdata\n",
    "# D.data = data\n",
    "# D.raw_target = elist\n",
    "# D.filesnames = filenames\n",
    "# D.numTweets = Len\n",
    "\n",
    "# fullfile = os.path.expanduser(\"~/Dropbox/insight/Twitter/\"+'train_data_XV_75x5k.p')\n",
    "# with open(fullfile, 'rb') as fp:\n",
    "#     T = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fullfile = os.path.expanduser(\"~/Dropbox/insight/Twitter/\"+'tweet_data_75x_unique_singles_target1d.p')\n",
    "\n",
    "# fullfile = os.path.expanduser(\"~/Dropbox/insight/Twitter/\"+'tweet_data_75x5k.p')\n",
    "with open(fullfile, 'rb') as fp:\n",
    "    D = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load emoji list\n",
    "fullfile = os.path.expanduser(\"~/Dropbox/insight/Emoji/\"+'mySmileys.p')\n",
    "with open(fullfile, 'rb') as fp:\n",
    "    emoji_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'data',\n",
       " 'filenames',\n",
       " 'numTweets',\n",
       " 'raw_data',\n",
       " 'raw_target',\n",
       " 'target_1d',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optional now: get 1-D target\n",
    "# numEmojis = len(D.target_names)\n",
    "# arr = []\n",
    "# for i in range(numEmojis):\n",
    "#     arr.extend([i] * D.numTweets[i]) \n",
    "# target_1d = np.array(arr, dtype=int)\n",
    "# D.target_1d = target_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in training and test set:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    D.data, D.target_1d, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308887, 215757)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK: Build a vectorizer that splits strings into sequence of 1 to 3\n",
    "# characters instead of word tokens\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char',\n",
    "#                              use_idf=False)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='word',min_df=3,#max_features = 20000,\n",
    "                             use_idf=True)\n",
    "\n",
    "XV_train = vectorizer.fit_transform(D.data)\n",
    "XV_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154443,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [308887, 154443]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-249357dce075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXV_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    584\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/insight/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/insight/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/insight/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [308887, 154443]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3)\n",
    "clf.fit(XV_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7420083784956262"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(XV_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154444, 109368)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XV_test = vectorizer.transform(X_test)\n",
    "XV_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(XV_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 109368)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coef = clf.coef_\n",
    "Coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09985496361140607"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(XV_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          😀       0.09      0.09      0.09      1697\n",
      "          😁       0.05      0.08      0.06      2223\n",
      "          😂       0.07      0.05      0.06      2546\n",
      "          🤣       0.05      0.06      0.06      1320\n",
      "          😃       0.09      0.10      0.09      2000\n",
      "          😄       0.12      0.08      0.10      1893\n",
      "          😅       0.04      0.05      0.05      1929\n",
      "          😆       0.06      0.04      0.05      1677\n",
      "          😉       0.07      0.07      0.07      1946\n",
      "          😊       0.08      0.13      0.10      2234\n",
      "          😋       0.14      0.13      0.13      2038\n",
      "          😎       0.12      0.13      0.12      1959\n",
      "          😍       0.13      0.08      0.10      2210\n",
      "          😘       0.11      0.11      0.11      2003\n",
      "          😗       0.09      0.10      0.10       998\n",
      "          😙       0.12      0.14      0.13      2019\n",
      "          😚       0.12      0.08      0.10      1757\n",
      "         ☺️       0.07      0.08      0.07      2209\n",
      "          🙂       0.10      0.07      0.08      2413\n",
      "          🤗       0.09      0.07      0.08      2021\n",
      "          🤔       0.09      0.11      0.10      1832\n",
      "          😐       0.07      0.08      0.07      2347\n",
      "          😑       0.09      0.07      0.08      2694\n",
      "          😶       0.05      0.06      0.06      1704\n",
      "          🙄       0.07      0.07      0.07      2698\n",
      "          😏       0.06      0.06      0.06      2104\n",
      "          😣       0.06      0.06      0.06      2425\n",
      "          😥       0.06      0.07      0.06      1475\n",
      "          😮       0.11      0.13      0.12      1760\n",
      "          🤐       0.15      0.16      0.15      1454\n",
      "          😯       0.18      0.18      0.18      1708\n",
      "          😪       0.10      0.07      0.08      2918\n",
      "          😫       0.07      0.05      0.06      2198\n",
      "          😴       0.22      0.20      0.21      2636\n",
      "          😌       0.10      0.09      0.09      2439\n",
      "          😛       0.10      0.11      0.10      2330\n",
      "          😜       0.07      0.05      0.06      1917\n",
      "          😝       0.07      0.07      0.07      2087\n",
      "          🤤       0.16      0.13      0.14      2103\n",
      "          😒       0.09      0.06      0.07      2657\n",
      "          😓       0.07      0.10      0.08      2533\n",
      "          😔       0.07      0.07      0.07      2897\n",
      "          😕       0.09      0.07      0.08      2663\n",
      "          🙃       0.07      0.07      0.07      2444\n",
      "          🤑       0.25      0.27      0.26      1899\n",
      "          😲       0.08      0.10      0.09      1391\n",
      "         ☹️       0.10      0.08      0.09      2977\n",
      "          🙁       0.09      0.06      0.07      2424\n",
      "          😖       0.07      0.09      0.08      2280\n",
      "          😞       0.07      0.08      0.08      2777\n",
      "          😟       0.08      0.08      0.08      2109\n",
      "          😤       0.12      0.09      0.10      2396\n",
      "          😢       0.08      0.07      0.08      1992\n",
      "          😭       0.05      0.04      0.04      1918\n",
      "          😦       0.07      0.09      0.08      1698\n",
      "          😧       0.06      0.07      0.07      1629\n",
      "          😨       0.06      0.11      0.07      1945\n",
      "          😩       0.06      0.07      0.07      2293\n",
      "          😬       0.06      0.06      0.06      2036\n",
      "          😰       0.09      0.07      0.08      1411\n",
      "          😱       0.11      0.11      0.11      1160\n",
      "          😳       0.07      0.06      0.06      1419\n",
      "          😵       0.10      0.08      0.09      1582\n",
      "          😡       0.11      0.08      0.09      1554\n",
      "          😠       0.09      0.08      0.09      1466\n",
      "          😷       0.11      0.13      0.12      2153\n",
      "          🤒       0.20      0.21      0.20      2343\n",
      "          🤕       0.13      0.10      0.11      1669\n",
      "          🤢       0.21      0.18      0.19      2675\n",
      "          🤧       0.10      0.07      0.08      2195\n",
      "          😇       0.12      0.17      0.14      1950\n",
      "          🤠       0.13      0.19      0.16      2143\n",
      "          🤡       0.16      0.22      0.18      1488\n",
      "          🤥       0.28      0.38      0.32      2119\n",
      "          🤓       0.16      0.12      0.14      2238\n",
      "\n",
      "avg / total       0.10      0.10      0.10    154444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_predict,\n",
    "                                    target_names=emoji_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c1fcfef305df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# coef_ : array, shape (1, n_features) or (n_classes, n_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mCoef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "Coef = clf.coef_\n",
    "# coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
    "\n",
    "Coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullfile = os.path.expanduser(\"~/Dropbox/insight_datadir/5k/\"+'outfile'+'🤓'+'.p')\n",
    "with open(fullfile, 'rb') as fp:\n",
    "    Tweets1 = pickle.load(fp)\n",
    "    \n",
    "fullfile = os.path.expanduser(\"~/Dropbox/insight_datadir/5k/\"+'outfile'+'🤡'+'.p')\n",
    "with open(fullfile, 'rb') as fp:\n",
    "    Tweets2 = pickle.load(fp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT @coinbundlecom: Why is crypto’s paper counterpart so important for the world of digital assets? Well, you’ll just have to fi(at)nd out f…', 'Nothing makes me happier than seeing Latinos/Hispanics succeed in life. #SiSePuede 🇲🇽🤓💪🏼', 'back to college in January! 🤓📚', 'Sebbo it is because u might take me for #SiestaWednesdays 😅😁🤓 https://t.co/lGxdG3ZK6E']\n"
     ]
    }
   ],
   "source": [
    "print(Tweets1[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (insight)",
   "language": "python",
   "name": "insight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
