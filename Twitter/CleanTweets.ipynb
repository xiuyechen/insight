{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['😀', '😁', '😂', '🤣', '😃', '😄', '😅', '😆', '😉', '😊', '😋', '😎', '😍', '😘', '😗', '😙', '😚', '☺️', '🙂', '🤗', '🤔', '😐', '😑', '😶', '🙄', '😏', '😣', '😥', '😮', '🤐', '😯', '😪', '😫', '😴', '😌', '😛', '😜', '😝', '🤤', '😒', '😓', '😔', '😕', '🙃', '🤑', '😲', '☹️', '🙁', '😖', '😞', '😟', '😤', '😢', '😭', '😦', '😧', '😨', '😩', '😬', '😰', '😱', '😳', '😵', '😡', '😠', '😷', '🤒', '🤕', '🤢', '🤧', '😇', '🤠', '🤡', '🤥', '🤓']\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "# load emoji list\n",
    "fullfile = os.path.expanduser(\"~/Dropbox/insight/Emoji/\"+'mySmileys.p')\n",
    "with open(fullfile, 'rb') as fp:\n",
    "    L = pickle.load(fp)\n",
    "print(L)\n",
    "print(len(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# tweet = \"RT @aa RT @bbb https:__ and other words httpsaa\" #RawT[-1]\n",
    "\n",
    "# b1 = re.findall(r'@\\S*', tweet) # Twitter user names\n",
    "# b2 = re.findall(r'RT\\S*', tweet) # \"RT\"\n",
    "# b3 = re.findall(r'http\\S*', tweet) # \"RT\"\n",
    "\n",
    "# c = tweet #list(tweet.split())\n",
    "# for b in b1:\n",
    "#     c = re.sub(b,\"\",c)\n",
    "# for b in b2:\n",
    "#     c = re.sub(b,\"\",c)\n",
    "# for b in b3:\n",
    "#     c = re.sub(b,\"\",c)\n",
    "# print(c) # OUTPUT:  and other words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN\n",
    "target_names = L\n",
    "\n",
    "# OUT\n",
    "rawdata = []\n",
    "data = []\n",
    "elist = []\n",
    "Len = []\n",
    "filenames = []\n",
    "\n",
    "# main loop\n",
    "for keyword in target_names:\n",
    "    fullfile = os.path.expanduser(\"~/Dropbox/insight_datadir/5k/\"+'outfile'+keyword+'.p')\n",
    "    with open(fullfile, 'rb') as fp:\n",
    "        itemlist = pickle.load(fp)\n",
    "        Len.append(len(itemlist))\n",
    "        \n",
    "        T = []\n",
    "        RawT = []\n",
    "        E = []\n",
    "        for tweet in itemlist:\n",
    "            # save raw tweet\n",
    "            RawT.append(tweet)\n",
    "            # take out all emojis from input tweets\n",
    "            emoji_list = extract_emojis(tweet)\n",
    "            E.append(emoji_list)\n",
    "            # save sanitized text\n",
    "            text = re.sub(\"|\".join(emoji_list), \"\", tweet)\n",
    "            T.append(text)\n",
    "        data = data + T\n",
    "        rawdata = rawdata + RawT\n",
    "        elist = elist + E\n",
    "        filenames = filenames + [fullfile]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tweet_data:\n",
    "    pass\n",
    "\n",
    "D = tweet_data()\n",
    "D.raw_data = rawdata\n",
    "D.data = data\n",
    "D.raw_target = elist\n",
    "D.filesnames = filenames\n",
    "D.numTweets = Len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullfile = os.path.expanduser(\"~/Dropbox/insight/Twitter/\"+'tweets_75x5k.p')\n",
    "with open(fullfile, 'wb') as fp:\n",
    "    pickle.dump(D, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numEmojis = len(target_names)\n",
    "arr = []\n",
    "for i in range(numEmojis):\n",
    "    arr.extend([i] * D.numTweets[i]) \n",
    "target = np.array(arr, dtype=int)\n",
    "\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tweet_train:\n",
    "    pass\n",
    "T = tweet_train()\n",
    "T.target_names = target_names\n",
    "T.data = D.data\n",
    "T.filenames = filenames\n",
    "T.target = target\n",
    "\n",
    "fullfile = os.path.expanduser(\"~/Dropbox/insight/Twitter/\"+'tweets_75x5k.p')\n",
    "with open(fullfile, 'wb') as fp:\n",
    "    pickle.dump(D, fp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (insight)",
   "language": "python",
   "name": "insight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
